{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Manipolazione e classificazione di immagini con OpenCV\n\n**OpenCV** è la libreria di riferimento per l'analisi e l'elaborazione di immagini in tempo reale in Python.\\ \nInstalliamola nel nostro ambiente JupyterLite",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "%pip install opencv-python",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "**numpy** è un modulo fondamentale per elaborare lunghe serie di numeri organizzati in liste e strutture N-dimensionali.\\\nInstalliamolo",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "%pip install numpy",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Adesso possiamo importare i moduli",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nfrom glob import glob",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "  Il metodo `glob` crea una **lista** con il nome dei files di una directory",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "dog_files = glob('training/dogs/*.jpg')\ncat_files = glob('training/cats/*.jpg')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Visualizzazione delle immagini\n\nSappiamo già che le immagini sono fatte di pixel. Il pixel è una unità di informazione che contiene i dati necessari a visualizzare un punto dell'immagine.\n\nVediamo come OpenCV rappresenta un immagine. Prendiamo l'elemento 20 della lista dei files dei \"cats\".",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "cat = cv2.imread(cat_files[20])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "cat",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "OpenCV rappresenta l'immagine come un 3-array, cioè un array a 3 dimensioni di numpy.\n\nL'attributo `shape` dell' N-array di `numpy` ci mostra la struttura di questo 3-array",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "cat.shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Sostanzialmente lo possiamo vedere come una lista-di-liste-di-liste, in cui \n- La lista di primo livello contiene le **righe** dell'immagine come liste\n- ciascuna lista di riga contiene la **lista dei pixel** della riga\n- Ciascun elemento della riga è una **lista a 3 valori**: contiene i valori di intensità dei tre colori fondamentali di cascun pixel nella forma **BGR** (blue, green, red). Le intensità sono rappresnetate da un BYTE, per cui il valore è un **intero tra 0 e 255**\n\nPerciò questa immagine ha 270 righe e 286 pixel per riga (270 x 286)\n\nUtilizziamo MatplotLib per visualizzare l'immagine.\\\nSiccome Matplotlib usa lo standard RGB, dovremo convertire da BGR ad RGB, con un metodo di conversione",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "cat_rgb = cv2.cvtColor(cat, cv2.COLOR_BGR2RGB)\nfig, ax = plt.subplots(figsize=(6,6))\nax.imshow(cat_rgb)\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## I canali RGB\n\nImmaginiamo di estrarre dal 3-array dell'immagine, TRE 2-array che contiene, ciascuno, uno dei 3 elementi più interni del 3-array.\\\nQuesti tre 2-array rappresentano le intensità di ciascun colore BLUE, GREED e RED immaginando che nell'immagine ci sia SOLO quel colore.\n\nQueste stre strutture rappresentano i **canali colore** dell'immagine, che possiamo visualizzare singolarmente",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "fig, ax2 = plt.subplots(1,3,figsize=(15,5))\nax2[0].imshow(cat[:,:,0], cmap='Blues')\nax2[1].imshow(cat[:,:,1], cmap='Greens')\nax2[2].imshow(cat[:,:,2], cmap='Reds')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Processamento delle immagini",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Conversione in scala di grigio\n\nLa riduzione dei dati rappresentativi di un immagine è un operazione frequente, quando dell'immagine ci interessanpo più le forme che i colori.\n\nVediamo questa nuova immagine",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "dog = cv2.imread(dog_files[26])\ndog_rgb = cv2.cvtColor(dog, cv2.COLOR_BGR2RGB)\nfig, ax = plt.subplots(figsize=(6,6))\nax.imshow(dog_rgb)\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Una di queste operazioni è la **conversione in scala di grigi**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "dog_gray = cv2.cvtColor(dog, cv2.COLOR_BGR2GRAY)\nfig, ax = plt.subplots(figsize=(6,6))\nax.imshow(dog_gray[:,:], cmap='Greys')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Vediamo come è rappresentata questa immagine da OpenCV",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "dog_gray",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "dog_gray.shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Vediamo che abbiamo un 2-array. Cosa rappresenta?",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Questa conversione ha prodotto un'immagine negativa, perchè l'intensità del grigio è minima nei punti bianchi.\n\nSe ricordiamo che i valori dei pixel sono BYTES che vanno da 0 a 255, come possiamo ripottarla al positivo?\n\nPossiamo sostituire ad ogni valore il risultato di (255 - quel valore)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "all_white = np.full((488, 499), 255)\ndog_gray_pos = all_white - dog_gray\nfig, ax = plt.subplots(figsize=(6,6))\nax.imshow(dog_gray_pos[:,:], cmap='Greys')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Ridimensionamento\n\nAnche il ridimensionamento è una operazione frequente, as esempio, quando dobbiamo elaborare una immagine con un programma che si aspetta una certa dimensione massima in pixel delle immagini.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "dog_resized = cv2.resize(dog_rgb, None, fx=0.25, fy=0.25)\nfig, ax = plt.subplots(figsize=(6,6))\nax.imshow(dog_resized[:,:])\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Questa prima chiamata al metodo `.resize()` opera un ridimensionamento proporzionale su X e Y.\\\nL'immagine si è sgranata (si dice \"pixelata\") perchè un minor numero di pixel è stato espanso sulla stessa dimensione in pollici del subplot.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "dog_resized.shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Vediamo ora una scalatura diversa, che ridimensiona l'immagine su dimensioni prefissate su righe e colonne",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "dog_resized = cv2.resize(dog_rgb, (100,200))\nfig, ax = plt.subplots(figsize=(6,6))\nax.imshow(dog_resized[:,:])\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "dog_resized.shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "# Rilevamento di oggetti o persone\n\nIl rilevamento di oggetti e persone è una delle applicazioni piu frequenti di algoritmi AI che utilizzano reti neurali.\\\n\nIl programma della prossima cella rileva il volto di una persona davanti alla webcam e circonda con un quadrato sia il volto che gli occhi.\\\nO meglio, quello che l'algoritmo ritiene somigliare ad occhi.\n\nPer prima cosa scarichiamo i due **modelli pre-addestrati** dei link seguenti (File -> Open from URL...)\n- https://tech.agilioty.com/Day13/haarcascade_frontalface_default.xml\n- https://tech.agilioty.com/Day13/haarcascade_eye.xml\n\nOra, analizziamo il programma nel dettaglio, per capire l'approccio, e poi proviamolo.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport cv2\n\n# sorgente dei modelli: https://github.com/Itseez/opencv/tree/master/data/haarcascades\n\n# Caricamento dei modelli pre-addestrati:\n# https://github.com/Itseez/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml\nface_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n# https://github.com/Itseez/opencv/blob/master/data/haarcascades/haarcascade_eye.xml\neye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n\ncap = cv2.VideoCapture(0)\n\nwhile 1:\n    ret, img = cap.read()\n    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    faces = face_cascade.detectMultiScale(gray_img, 1.3, 5)\n\n    for (x,y,w,h) in faces:\n        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n        cut_gray = gray_img[y:y+h, x:x+w]\n        cut_color = img[y:y+h, x:x+w]\n        \n        eyes = eye_cascade.detectMultiScale(cut_gray)\n        for (ex,ey,ew,eh) in eyes:\n            cv2.rectangle(cut_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n\n    cv2.imshow('img',img)\n    k = cv2.waitKey(30) & 0xff\n# 27 = ESC\n    if k == 27:\n        break\n\ncap.release()\ncv2.destroyAllWindows()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}